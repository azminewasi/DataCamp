{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course - Preprocessing for Machine Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 -  Introduction to Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - rows\n",
    "Taking a look at the volunteer dataset again, we want to drop rows where the category_desc column values are missing. We're going to do this using boolean indexing, by checking to see if we have any null values, and then filtering the dataset so that we only have rows with those values.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Check how many values are missing in the category_desc column using isnull() and sum().\n",
    "Subset the volunteer dataset by indexing by where category_desc is notnull(), and store in a new variable called volunteer_subset.\n",
    "Take a look at the .shape attribute of the new dataset, to verify it worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many values are missing in the category_desc column\n",
    "print(volunteer[\"category_desc\"].isnull().sum())\n",
    "\n",
    "# Subset the volunteer dataset\n",
    "volunteer_subset = volunteer[volunteer[\"category_desc\"].notnull()]\n",
    "\n",
    "# Print out the shape of the subset\n",
    "print(volunteer_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a column type\n",
    "If you take a look at the volunteer dataset types, you'll see that the column hits is type object. But, if you actually look at the column, you'll see that it consists of integers. Let's convert that column to type int.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Take a look at the .head() of the hits column.\n",
    "Use the .astype function to convert the column to type int.\n",
    "Take a look at the dtypes of the dataset again, and notice that the column type has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the head of the hits column\n",
    "print(volunteer[\"hits\"].head())\n",
    "\n",
    "# Convert the hits column to type int\n",
    "volunteer[\"hits\"] = volunteer[\"hits\"].astype(\"int\")\n",
    "\n",
    "# Look at the dtypes of the dataset\n",
    "print(volunteer.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified sampling\n",
    "We know that the distribution of variables in the category_desc column in the volunteer dataset is uneven. If we wanted to train a model to try to predict category_desc, we would want to train the model on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a volunteer_X dataset with all of the columns except category_desc.\n",
    "Create a volunteer_y training labels dataset.\n",
    "Split up the volunteer_X dataset using scikit-learn's train_test_split function and passing volunteer_y into the stratify= parameter.\n",
    "Take a look at the category_desc value counts on the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data with all columns except category_desc\n",
    "volunteer_X = volunteer.drop(\"category_desc\", axis=1)\n",
    "\n",
    "# Create a category_desc labels dataset\n",
    "volunteer_y = volunteer[[\"category_desc\"]]\n",
    "\n",
    "# Use stratified sampling to split up the dataset according to the volunteer_y dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y)\n",
    "\n",
    "# Print out the category_desc counts on the training y labels\n",
    "print(y_train[\"category_desc\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
