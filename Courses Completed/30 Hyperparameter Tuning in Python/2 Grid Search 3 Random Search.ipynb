{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course - Hyperparameter Tuning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2 Grid Search, 3 Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Grid Search functions\n",
    "In data science it is a great idea to try building algorithms, models and processes 'from scratch' so you can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give you a great edge in your data science work.\n",
    "\n",
    "In this exercise, you will create a function to take in 2 hyperparameters, build models and return results. You will use this function in a future exercise.\n",
    "\n",
    "You will have available the X_train, X_test, y_train and y_test datasets available.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Build a function that takes two parameters called learning_rate and max_depth for the learning rate and maximum depth.\n",
    "Add capability in the function to build a GBM model and fit it to the data with the input hyperparameters.\n",
    "Have the function return the results of that model and the chosen hyperparameters (learning_rate and max_depth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function\n",
    "def gbm_grid_search(learning_rate, max_depth):\n",
    "\n",
    "\t# Create the model\n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate, max_depth=max_depth)\n",
    "    \n",
    "    # Use the model to make predictions\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Return the hyperparameters and score\n",
    "    return([learning_rate, max_depth, accuracy_score(y_test,predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively tune multiple hyperparameters\n",
    "In this exercise, you will build on the function you previously created to take in 2 hyperparameters, build a model and return the results. You will now use that to loop through some values and then extend this function and loop with another hyperparameter.\n",
    "\n",
    "The function gbm_grid_search(learn_rate, max_depth) is available in this exercise.\n",
    "\n",
    "If you need to remind yourself of the function you can run the function print_func() that has been created for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the relevant lists\n",
    "results_list = []\n",
    "learn_rate_list = [0.01, 0.1, 0.5]\n",
    "max_depth_list = [2, 4, 6]\n",
    "\n",
    "# Create the for loop\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        results_list.append(gbm_grid_search(learn_rate, max_depth))\n",
    "\n",
    "# Print the results\n",
    "print(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Grid Search functions\n",
    "In data science it is a great idea to try building algorithms, models and processes 'from scratch' so you can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give you a great edge in your data science work.\n",
    "\n",
    "In this exercise, you will create a function to take in 2 hyperparameters, build models and return results. You will use this function in a future exercise.\n",
    "\n",
    "You will have available the X_train, X_test, y_train and y_test datasets available.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Build a function that takes two parameters called learning_rate and max_depth for the learning rate and maximum depth.\n",
    "Add capability in the function to build a GBM model and fit it to the data with the input hyperparameters.\n",
    "Have the function return the results of that model and the chosen hyperparameters (learning_rate and max_depth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function\n",
    "def gbm_grid_search(learning_rate, max_depth):\n",
    "\n",
    "\t# Create the model\n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate, max_depth=max_depth)\n",
    "    \n",
    "    # Use the model to make predictions\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Return the hyperparameters and score\n",
    "    return([learning_rate, max_depth, accuracy_score(y_test,predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend your loop to call gbm_grid_search (available in your console), then test the values [0.4 , 0.6] for the subsample hyperparameter and print the results. max_depth_list & learn_rate_list are available in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "# Create the new list to test\n",
    "subsample_list = [0.4 , 0.6] \n",
    "\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "    \n",
    "    \t# Extend the for loop\n",
    "        for subsample in subsample_list:\n",
    "        \t\n",
    "            # Extend the results to include the new hyperparameter\n",
    "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\n",
    "            \n",
    "# Print results\n",
    "print(results_list)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV with Scikit Learn\n",
    "The GridSearchCV module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. You will now put your learning into practice by creating a GridSearchCV object with certain parameters.\n",
    "\n",
    "The desired options are:\n",
    "\n",
    "A Random Forest Estimator, with the split criterion as 'entropy'\n",
    "5-fold cross validation\n",
    "The hyperparameters max_depth (2, 4, 8, 15) and max_features ('auto' vs 'sqrt')\n",
    "Use roc_auc to score the models\n",
    "Use 4 cores for processing in parallel\n",
    "Ensure you refit the best model and return training scores\n",
    "You will have available X_train, X_test, y_train & y_test datasets.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a Random Forest estimator as specified in the context above.\n",
    "Create a parameter grid as specified in the context above.\n",
    "Create a GridSearchCV object as outlined in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier with specified criterion\n",
    "rf_class = RandomForestClassifier(criterion ='entropy')\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {\"max_depth\": [2, 4, 8, 15], \"max_features\": [\"auto\",\"sqrt\"]} \n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_rf_class = GridSearchCV(\n",
    "    estimator=rf_class,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    refit=True, return_train_score=True)\n",
    "print(grid_rf_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the grid search results\n",
    "You will now explore the cv_results_ property of the GridSearchCV object defined in the video. This is a dictionary that we can read into a pandas DataFrame and contains a lot of useful information about the grid search we just undertook.\n",
    "\n",
    "A reminder of the different column types in this property:\n",
    "\n",
    "time_ columns\n",
    "param_ columns (one for each hyperparameter) and the singular params column (with all hyperparameter settings)\n",
    "a train_score column for each cv fold including the mean_train_score and std_train_score columns\n",
    "a test_score column for each cv fold including the mean_test_score and std_test_score columns\n",
    "a rank_test_score column with a number from 1 to n (number of iterations) ranking the rows based on their mean_test_score\n",
    "Instructions\n",
    "100 XP\n",
    "Read the cv_results_ property of the grid_rf_class GridSearchCV object into a data frame & print the whole thing out to inspect.\n",
    "Extract & print the singular column containing a dictionary of all hyperparameters used in each iteration of the grid search.\n",
    "Extract & print the row that had the best mean test score by indexing using the rank_test_score column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cv_results property into a dataframe & print it out\n",
    "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
    "print(cv_results_df)\n",
    "\n",
    "# Extract and print the column with a dictionary of hyperparameters used\n",
    "column = cv_results_df.loc[:, [\"params\"]]\n",
    "print(column)\n",
    "\n",
    "# Extract and print the row that had the best mean test score\n",
    "best_row = cv_results_df[cv_results_df['rank_test_score'] == 1 ]\n",
    "print(best_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the best results\n",
    "At the end of the day, we primarily care about the best performing 'square' in a grid search. Luckily Scikit Learn's gridSearchCv objects have a number of parameters that provide key information on just the best square (or row in cv_results_).\n",
    "\n",
    "Three properties you will explore are:\n",
    "\n",
    "best_score_ – The score (here ROC_AUC) from the best-performing square.\n",
    "best_index_ – The index of the row in cv_results_ containing information on the best-performing square.\n",
    "best_params_ – A dictionary of the parameters that gave the best score, for example 'max_depth': 10\n",
    "The grid search object grid_rf_class is available.\n",
    "\n",
    "A dataframe (cv_results_df) has been created from the cv_results_ for you on line 6. This will help you index into the results.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Extract and print out the ROC_AUC score from the best performing square in grid_rf_class.\n",
    "Create a variable from the best-performing row by indexing into cv_results_df.\n",
    "Create a variable, best_n_estimators by extracting the n_estimators parameter from the best-performing square in grid_rf_class and print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the ROC_AUC score from the best-performing square\n",
    "best_score = grid_rf_class.best_score_\n",
    "print(best_score)\n",
    "\n",
    "# Create a variable from the row related to the best-performing square\n",
    "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
    "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
    "print(best_row)\n",
    "\n",
    "# Get the n_estimators parameter from the best-performing square and print\n",
    "best_n_estimators = grid_rf_class.best_params_[\"n_estimators\"]\n",
    "print(best_n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Sample Hyperparameters\n",
    "To undertake a random search, we firstly need to undertake a random sampling of our hyperparameter space.\n",
    "\n",
    "In this exercise, you will firstly create some lists of hyperparameters that can be zipped up to a list of lists. Then you will randomly sample hyperparameter combinations preparation for running a random search.\n",
    "\n",
    "You will use just the hyperparameters learning_rate and min_samples_leaf of the GBM algorithm to keep the example illustrative and not overly complicated.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a list of 200 values for the learning_rate hyperparameter between 0.01 and 1.5 and assign to the list learn_rate_list.\n",
    "Create a list of values between 10 and 40 inclusive for the hyperparameter min_samples_leaf and assign to the list min_samples_list.\n",
    "Combine these lists into a list of lists to sample from.\n",
    "Randomly sample 250 models from these hyperparameter combinations and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "250# Create a list of values for the learning_rate hyperparameter\n",
    "learn_rate_list = list(np.linspace(0.01,1.5,200))\n",
    "\n",
    "# Create a list of values for the min_samples_leaf hyperparameter\n",
    "min_samples_list = list(range(10,41))\n",
    "\n",
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]\n",
    "\n",
    "# Sample hyperparameter combinations for a random search.\n",
    "random_combinations_index = np.random.choice(range(0, len(combinations_list)), 250, replace=False)\n",
    "combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
    "\n",
    "# Print the result\n",
    "print(combinations_random_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Search with Random Forest\n",
    "To solidify your knowledge of random sampling, let's try a similar exercise but using different hyperparameters and a different algorithm.\n",
    "\n",
    "As before, create some lists of hyperparameters that can be zipped up to a list of lists. You will use the hyperparameters criterion, max_depth and max_features of the random forest algorithm. Then you will randomly sample hyperparameter combinations in preparation for running a random search.\n",
    "\n",
    "You will use a slightly different package for sampling in this task, random.sample().\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create lists of the values 'gini' and 'entropy' for criterion & \"auto\", \"sqrt\", \"log2\", None for max_features.\n",
    "Create a list of values between 3 and 55 inclusive for the hyperparameter max_depth and assign to the list max_depth_list. Remember that range(N,M) will create a list from N to M-1.\n",
    "Combine these lists into a list of lists to sample from using product().\n",
    "Randomly sample 150 models from the combined list and print the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for criterion and max_features\n",
    "criterion_list = ['gini','entropy']\n",
    "max_feature_list = [\"auto\", \"sqrt\", \"log2\", None]\n",
    "\n",
    "# Create a list of values for the max_depth hyperparameter\n",
    "max_depth_list = list(range(3,56))\n",
    "\n",
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(criterion_list,max_feature_list , max_depth_list)]\n",
    "\n",
    "# Sample hyperparameter combinations for a random search\n",
    "combinations_random_chosen = random.sample(combinations_list, 150)\n",
    "\n",
    "# Print the result\n",
    "print(combinations_random_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Random Search\n",
    "Visualizing the search space of random search allows you to easily see the coverage of this technique and therefore allows you to see the effect of your sampling on the search space.\n",
    "\n",
    "In this exercise you will use several different samples of hyperparameter combinations and produce visualizations of the search space.\n",
    "\n",
    "The function sample_and_visualize_hyperparameters() takes a single argument (number of combinations to sample) and then randomly samples hyperparameter combinations, just like you did in the last exercise! The function will then visualize the combinations.\n",
    "\n",
    "If you want to see the function definition, you can use Python's handy inspect library, like so:\n",
    "\n",
    "print(inspect.getsource(sample_and_visualize_hyperparameters))\n",
    "\n",
    "Instructions\n",
    "\n",
    "Confirm how many possible hyperparameter combinations there are in combinations_list by assigning to the variable number_combs and print this out.\n",
    "Sample and visualize 50, 500 and 1500 combinations. You will use a loop for succinctness. What do you notice about the visualization?\n",
    "Now sample and visualize the entire set of combinations. You have already made a variable to assist with this. What does this look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm how many hyperparameter combinations & print\n",
    "number_combs = len(combinations_list)\n",
    "print(number_combs)\n",
    "\n",
    "# Sample and visualise specified combinations\n",
    "for x in [50, 500,1500]:\n",
    "    sample_and_visualize_hyperparameters(x)\n",
    "    \n",
    "# Sample all the hyperparameter combinations & visualise\n",
    "sample_and_visualize_hyperparameters(number_combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RandomizedSearchCV Object\n",
    "Just like the GridSearchCV library from Scikit Learn, RandomizedSearchCV provides many useful features to assist with efficiently undertaking a random search. You're going to create a RandomizedSearchCV object, making the small adjustment needed from the GridSearchCV object.\n",
    "\n",
    "The desired options are:\n",
    "\n",
    "A default Gradient Boosting Classifier Estimator\n",
    "5-fold cross validation\n",
    "Use accuracy to score the models\n",
    "Use 4 cores for processing in parallel\n",
    "Ensure you refit the best model and return training scores\n",
    "Randomly sample 10 models\n",
    "The hyperparameter grid should be for learning_rate (150 values between 0.1 and 2) and min_samples_leaf (all values between and including 20 and 64).\n",
    "\n",
    "You will have available X_train & y_train datasets.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a parameter grid as specified in the context above.\n",
    "Create a RandomizedSearchCV object as outlined in the context above.\n",
    "Fit the RandomizedSearchCV object to the training data.\n",
    "Print the values chosen by the modeling process for both hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'learning_rate': np.linspace(0.1,2,150), 'min_samples_leaf': list(range(20,65))} \n",
    "\n",
    "# Create a random search object\n",
    "random_GBM_class = RandomizedSearchCV(\n",
    "    estimator = GradientBoostingClassifier(),\n",
    "    param_distributions = param_grid,\n",
    "    cv = 5,\n",
    "    scoring='accuracy', n_jobs=4, n_iter = 10, refit=True, return_train_score = True)\n",
    "\n",
    "# Fit to the training data\n",
    "random_GBM_class.fit(X_train, y_train)\n",
    "\n",
    "# Print the values used for both hyperparameters\n",
    "print(random_GBM_class.cv_results_['param_learning_rate'])\n",
    "print(random_GBM_class.cv_results_['param_min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV in Scikit Learn\n",
    "Let's practice building a RandomizedSearchCV object using Scikit Learn.\n",
    "\n",
    "The hyperparameter grid should be for max_depth (all values between and including 5 and 25) and max_features ('auto' and 'sqrt').\n",
    "\n",
    "The desired options for the RandomizedSearchCV object are:\n",
    "\n",
    "A RandomForestClassifier Estimator with n_estimators of 80.\n",
    "3-fold cross validation (cv)\n",
    "Use roc_auc to score the models\n",
    "Use 4 cores for processing in parallel (n_jobs)\n",
    "Ensure you refit the best model and return training scores\n",
    "Only sample 5 models for efficiency (n_iter)\n",
    "X_train & y_train datasets are loaded for you.\n",
    "\n",
    "Remember, to extract the chosen hyperparameters these are found in cv_results_ with a column per hyperparameter. For example, the column for the hyperparameter criterion would be param_criterion.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a hyperparameter grid as specified in the context above.\n",
    "Create a RandomizedSearchCV object as outlined in the context above.\n",
    "Fit the RandomizedSearchCV object to the training data.\n",
    "Index into the cv_results_ object to print the values chosen by the modeling process for both hyperparameters (max_depth and max_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto','sqrt']} \n",
    "\n",
    "# Create a random search object\n",
    "random_rf_class = RandomizedSearchCV(\n",
    "    estimator = RandomForestClassifier(n_estimators=80),\n",
    "    param_distributions = param_grid, n_iter = 5,\n",
    "    scoring='roc_auc', n_jobs=4, cv = 3, refit=True, return_train_score = True )\n",
    "\n",
    "# Fit to the training data\n",
    "random_rf_class.fit(X_train, y_train)\n",
    "\n",
    "# Print the values used for both hyperparameters\n",
    "print(random_rf_class.cv_results_['param_max_depth'])\n",
    "print(random_rf_class.cv_results_['param_max_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Grid and Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid and Random Search Side by Side\n",
    "Visualizing the search space of random and grid search together allows you to easily see the coverage that each technique has and therefore brings to life their specific advantages and disadvantages.\n",
    "\n",
    "In this exercise, you will sample hyperparameter combinations in a grid search way as well as a random search way, then plot these to see the difference.\n",
    "\n",
    "You will have available:\n",
    "\n",
    "combinations_list which is a list of combinations of learn_rate and min_samples_leaf for this algorithm\n",
    "The function visualize_search() which will make your hyperparameter combinations into X and Y coordinates and plot both grid and random search combinations on the same graph. It takes as input two lists of hyperparameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample grid coordinates\n",
    "grid_combinations_chosen = combinations_list[0:300]\n",
    "\n",
    "# Create a list of sample indexes\n",
    "sample_indexes = list(range(0,len(combinations_list)))\n",
    "\n",
    "# Randomly sample 300 indexes\n",
    "random_indexes = np.random.choice(sample_indexes, 300, replace=False)\n",
    "\n",
    "# Use indexes to create random sample\n",
    "random_combinations_chosen = [combinations_list[index] for index in random_indexes]\n",
    "\n",
    "# Call the function to produce the visualization\n",
    "visualize_search(grid_combinations_chosen, random_combinations_chosen)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
