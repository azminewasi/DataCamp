{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course - Hyperparameter Tuning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 - Informed Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Logistic Regression parameter\n",
    "You are now going to practice extracting an important parameter of the logistic regression model. The logistic regression has a few other parameters you will not explore here but you can review them in the scikit-learn.org documentation for the LogisticRegression() module under 'Attributes'.\n",
    "\n",
    "This parameter is important for understanding the direction and magnitude of the effect the variables have on the target.\n",
    "\n",
    "In this exercise we will extract the coefficient parameter (found in the coef_ attribute), zip it up with the original column names, and see which variables had the largest positive effect on the target variable.\n",
    "\n",
    "You will have available:\n",
    "\n",
    "A logistic regression model object named log_reg_clf\n",
    "The X_train DataFrame\n",
    "sklearn and pandas have been imported for you.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a list of the original column names used in the training DataFrame.\n",
    "Extract the coefficients of the logistic regression estimator.\n",
    "Create a DataFrame of coefficients and variable names & view it.\n",
    "Print out the top 3 'positive' variables based on the coefficient size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of original variable names from the training DataFrame\n",
    "original_variables = X_train.columns\n",
    "\n",
    "# Extract the coefficients of the logistic regression estimator\n",
    "model_coefficients = log_reg_clf.coef_[0]\n",
    "\n",
    "# Create a dataframe of the variables and coefficients & print it out\n",
    "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \"Coefficient\": model_coefficients})\n",
    "print(coefficient_df)\n",
    "\n",
    "# Print out the top 3 positive variables\n",
    "top_three_df = coefficient_df.sort_values(by=\"Coefficient\", axis=0, ascending=False)[0:3]\n",
    "print(top_three_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Coarse to Fine\n",
    "You're going to undertake the first part of a Coarse to Fine search. This involves analyzing the results of an initial random search that took place over a large search space, then deciding what would be the next logical step to make your hyperparameter search finer.\n",
    "\n",
    "You have available:\n",
    "\n",
    "combinations_list - a list of the possible hyperparameter combinations the random search was undertaken on.\n",
    "results_df - a DataFrame that has each hyperparameter combination and the resulting accuracy of all 500 trials. Each hyperparameter is a column, with the header the hyperparameter name.\n",
    "visualize_hyperparameter() - a function that takes in a column of the DataFrame (as a string) and produces a scatter plot of this column's values compared to the accuracy scores. An example call of the function would be visualize_hyperparameter('accuracy')\n",
    "If you wish to view the visualize_hyperparameter() function definition, you can run this code:\n",
    "\n",
    "import inspect\n",
    "print(inspect.getsource(visualize_hyperparameter))\n",
    "\n",
    "Instructions\n",
    "\n",
    "Confirm (by printing out) the size of the combinations_list, justifying the need to start with a random search.\n",
    "Sort the results_df by accuracy values and print the top 10 rows. Are there clear insights? Beware a small sample size!\n",
    "Confirm (by printing out) which hyperparameters were used in this search. These are the column names in results_df.\n",
    "Call visualize_hyperparameter() with each hyperparameter in turn (max_depth, min_samples_leaf, learn_rate). Are there any trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the size of the combinations_list\n",
    "print(len(combinations_list))\n",
    "\n",
    "# Sort the results_df by accuracy and print the top 10 rows\n",
    "print(results_df.sort_values(by=\"accuracy\", ascending=False).head(10))\n",
    "\n",
    "# Confirm which hyperparameters were used in this search\n",
    "print(results_df.columns)\n",
    "\n",
    "# Call visualize_hyperparameter() with each hyperparameter in turn\n",
    "visualize_hyperparameter(\"max_depth\")\n",
    "visualize_hyperparameter(\"min_samples_leaf\")\n",
    "visualize_hyperparameter(\"learn_rate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse to Fine Iterations\n",
    "You will now visualize the first random search undertaken, construct a tighter grid and check the results. You will have available:\n",
    "\n",
    "results_df - a DataFrame that has the hyperparameter combination and the resulting accuracy of all 500 trials. Only the hyperparameters that had the strongest visualizations from the previous exercise are included (max_depth and learn_rate)\n",
    "visualize_first() - This function takes no arguments but will visualize each of your hyperparameters against accuracy for your first random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided function to visualize the first results\n",
    "# visualize_first()\n",
    "\n",
    "# Create some combinations lists & combine:\n",
    "max_depth_list = list(range(1,21))\n",
    "learn_rate_list = np.linspace(0.001,1,50)\n",
    "\n",
    "# Call the function to visualize the second results\n",
    "visualize_second()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informed Search: Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes Rule in Python\n",
    "In this exercise you will undertake a practical example of setting up Bayes formula, obtaining new evidence and updating your 'beliefs' in order to get a more accurate result. The example will relate to the likelihood that someone will close their account for your online software product.\n",
    "\n",
    "These are the probabilities we know:\n",
    "\n",
    "7% (0.07) of people are likely to close their account next month\n",
    "15% (0.15) of people with accounts are unhappy with your product (you don't know who though!)\n",
    "35% (0.35) of people who are likely to close their account are unhappy with your product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign probabilities to variables \n",
    "p_unhappy = 0.15\n",
    "p_unhappy_close = 0.35\n",
    "\n",
    "# Probabiliy someone will close\n",
    "p_close = 0.07\n",
    "\n",
    "# Probability unhappy person will close\n",
    "p_close_unhappy = (p_unhappy_close* p_close) /   p_unhappy\n",
    "print(p_close_unhappy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Hyperparameter tuning with Hyperopt\n",
    "In this example you will set up and run a Bayesian hyperparameter optimization process using the package Hyperopt (already imported as hp for you). You will set up the domain (which is similar to setting up the grid for a grid search), then set up the objective function. Finally, you will run the optimizer over 20 iterations.\n",
    "\n",
    "You will need to set up the domain using values:\n",
    "\n",
    "max_depth using quniform distribution (between 2 and 10, increasing by 2)\n",
    "learning_rate using uniform distribution (0.001 to 0.9)\n",
    "Note that for the purpose of this exercise, this process was reduced in data sample size and hyperopt & GBM iterations. If you are trying out this method by yourself on your own machine, try a larger search space, more trials, more cvs and a larger dataset size to really see this in action!\n",
    "\n",
    "Instructions\n",
    "\n",
    "Set up a space dictionary using the domain mentioned above.\n",
    "Set up the objective function using a gradient boosting classifier.\n",
    "Run the algorithm for 20 evaluations (just use the default, suggested algorithm from the slides)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up space dictionary with specified hyperparameters\n",
    "space = {'max_depth': hp.quniform('max_depth', 2, 10, 2),'learning_rate': hp.uniform('learning_rate', 0.001, 0.9)}\n",
    "\n",
    "# Set up objective function\n",
    "def objective(params):\n",
    "    params = {'max_depth': int(params['max_depth']),'learning_rate': params['learning_rate']}\n",
    "    gbm_clf = GradientBoostingClassifier(n_estimators=100, **params) \n",
    "    best_score = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=2, n_jobs=4).mean()\n",
    "    loss = 1 - best_score\n",
    "    return loss\n",
    "\n",
    "# Run the algorithm\n",
    "best = fmin(fn=objective,space=space, max_evals=20, rstate=np.random.default_rng(42), algo=tpe.suggest)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informed Search: Genetic Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Hyperparameter Tuning with TPOT\n",
    "You're going to undertake a simple example of genetic hyperparameter tuning. TPOT is a very powerful library that has a lot of features. You're just scratching the surface in this lesson, but you are highly encouraged to explore in your own time.\n",
    "\n",
    "This is a very small example. In real life, TPOT is designed to be run for many hours to find the best model. You would have a much larger population and offspring size as well as hundreds more generations to find a good model.\n",
    "\n",
    "You will create the estimator, fit the estimator to the training data and then score this on the test data.\n",
    "\n",
    "For this example we wish to use:\n",
    "\n",
    "3 generations\n",
    "4 in the population size\n",
    "3 offspring in each generation\n",
    "accuracy for scoring\n",
    "A random_state of 2 has been set for consistency of results.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Assign the values outlined in the context to the inputs for tpot_clf.\n",
    "Create the tpot_clf classifier with the correct inputs.\n",
    "Fit the classifier to the training data (X_train & y_train are available in your workspace).\n",
    "Use the fitted classifier to score on the test set (X_test & y_test are available in your workspace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the values outlined to the inputs\n",
    "number_generations = 3\n",
    "population_size = 4\n",
    "offspring_size = 3\n",
    "scoring_function = \"accuracy\"\n",
    "\n",
    "# Create the tpot classifier\n",
    "tpot_clf = TPOTClassifier(generations=number_generations, population_size=population_size ,\n",
    "                          offspring_size=offspring_size, scoring=scoring_function ,\n",
    "                          verbosity=2, random_state=2, cv=2)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing TPOT's stability\n",
    "You will now see the random nature of TPOT by constructing the classifier with different random states and seeing what model is found to be best by the algorithm. This assists to see that TPOT is quite unstable when not run for a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tpot classifier \n",
    "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
    "                          verbosity=2, random_state=99)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
