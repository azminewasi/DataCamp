{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course - Manipulating Time Series Data in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2 Basic Time Series Metrics & Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare time series growth rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the performance of several asset classes\n",
    "You have seen in the video how you can easily compare several time series by normalizing their starting points to 100, and plot the result.\n",
    "\n",
    "To broaden your perspective on financial markets, let's compare four key assets: stocks, bonds, gold, and oil.\n",
    "\n",
    "Instructions\n",
    "\n",
    "We have already imported pandas as pd and matplotlib.pyplot as plt.\n",
    "\n",
    "- Import 'asset_classes.csv', using .read_csv() to parse dates in the 'DATE' column and set this column as the index, then assign the result to prices.\n",
    "- Select the first price for each series using .iloc[0] on prices and assign the result to first_prices.\n",
    "- Divide prices by first_prices, multiply by 100 and assign the result to normalized.\n",
    "- Plot normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "prices = pd.read_csv('asset_classes.csv', parse_dates=['DATE'], index_col='DATE')\n",
    "\n",
    "# Inspect prices here\n",
    "print(prices.info())\n",
    "\n",
    "# Select first prices\n",
    "first_prices = prices.iloc[0]\n",
    "\n",
    "# Create normalized\n",
    "normalized = prices/first_prices * 100\n",
    "\n",
    "# Plot normalized\n",
    "normalized.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing stock prices with a benchmark\n",
    "You also learned in the video how to compare the performance of various stocks against a benchmark. Now you'll learn more about the stock market by comparing the three largest stocks on the NYSE to the Dow Jones Industrial Average, which contains the 30 largest US companies.\n",
    "\n",
    "The three largest companies on the NYSE are:\n",
    "\n",
    "```\n",
    "Company\tStock Ticker\n",
    "Johnson & Johnson\tJNJ\n",
    "Exxon Mobil\tXOM\n",
    "JP Morgan Chase\tJPM\n",
    "```\n",
    "\n",
    "Instructions\n",
    "\n",
    "We have already imported pandas as pd and matplotlib.pyplot as plt.\n",
    "\n",
    "- Use pd.read_csv() to import 'nyse.csv' and 'dow_jones.csv', creating a DatetimeIndex for each from the 'date' column using parse_dates and index_col, and assign the result to stocks and dow_jones, respectively.\n",
    "- Use pd.concat() along axis=1 to combine stocks and dow_jones and assign the result to data. Inspect the .info() of data.\n",
    "- Divide data by the first value for each series, multiply by 100 and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stock prices and index here\n",
    "stocks = pd.read_csv('nyse.csv', parse_dates=['date'], index_col='date')\n",
    "dow_jones = pd.read_csv('dow_jones.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Concatenate data and inspect result here\n",
    "data = pd.concat([stocks, dow_jones], axis=1)\n",
    "print(data.info())\n",
    "\n",
    "# Normalize and plot your data here\n",
    "data.div(data.iloc[0]).mul(100).plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance difference vs benchmark index\n",
    "In the video, you learned how to calculate and plot the performance difference of a stock in percentage points relative to a benchmark index.\n",
    "\n",
    "Let's compare the performance of Microsoft (MSFT) and Apple (AAPL) to the S&P 500 over the last 10 years.\n",
    "\n",
    "Instructions\n",
    "\n",
    "- We have already imported pandas as pd and matplotlib.pyplot as plt.\n",
    "- Create the list tickers containing the two stock symbols.\n",
    "- Use pd.read_csv() to import 'msft_aapl.csv' and 'sp500.csv', creating a DatetimeIndex for each from the 'date' column using parse_dates and index_col, and assign the result to stocks and sp500, respectively.\n",
    "- Use pd.concat() to concatenate stocks and sp500 along axis=1, apply .dropna() to drop all missing values, and assign the result to data.\n",
    "- Normalize data by dividing by the first price, multiply by 100 and assign the output to normalized.\n",
    "- Select tickers from normalized, and subtract normalized['SP500'] with keyword axis=0 to align the indexes, then plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tickers\n",
    "tickers = ['MSFT', 'AAPL']\n",
    "\n",
    "# Import stock data here\n",
    "stocks = pd.read_csv('msft_aapl.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Import index here\n",
    "sp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Concatenate stocks and index here\n",
    "data = pd.concat([stocks, sp500], axis=1).dropna()\n",
    "\n",
    "# Normalize data\n",
    "normalized = data.div(data.iloc[0]).mul(100)\n",
    "\n",
    "# Subtract the normalized index from the normalized stock prices, and plot the result\n",
    "normalized[tickers].sub(normalized['SP500'], axis=0).plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the time series frequency: resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert monthly to weekly data\n",
    "You have learned in the video how to use .reindex() to conform an existing time series to a DateTimeIndex at a different frequency.\n",
    "\n",
    "Let's practice this method by creating monthly data and then converting this data to weekly frequency while applying various fill logic options.\n",
    "\n",
    "Instruction\n",
    "- We have already imported pandas as pd for you. We have also defined start and end dates.\n",
    "- Create monthly_dates using pd.date_range with start, end and frequency alias 'M'.\n",
    "- Create and print the pd.Series monthly, passing the list [1, 2] as the data argument, and using monthly_dates as index.\n",
    "- Create weekly_dates using pd.date_range with start, end and frequency alias 'W'.\n",
    "- Apply .reindex() to monthly three times: first without additional options, then with bfill and then with ffill, print()-ing each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end dates\n",
    "start = '2016-1-1'\n",
    "end = '2016-2-29'\n",
    "\n",
    "# Create monthly_dates here\n",
    "monthly_dates = pd.date_range(start=start ,end=end, freq='M')\n",
    "\n",
    "# Create and print monthly here\n",
    "monthly = pd.Series([1, 2],index=monthly_dates)\n",
    "print(monthly)\n",
    "\n",
    "# Create weekly_dates here\n",
    "weekly_dates = pd.date_range(start=start ,end=end, freq='W')\n",
    "\n",
    "# Print monthly, reindexed using weekly_dates\n",
    "print(monthly.reindex(weekly_dates))\n",
    "print(monthly.reindex(weekly_dates,method='bfill'))\n",
    "print(monthly.reindex(weekly_dates,method='ffill'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create weekly from monthly unemployment data\n",
    "The civilian US unemployment rate is reported monthly. You may need more frequent data, but that's no problem because you just learned how to upsample a time series.\n",
    "\n",
    "You'll work with the time series data for the last 20 years, and apply a few options to fill in missing values before plotting the weekly series.\n",
    "\n",
    "Instructions\n",
    "- We have already imported pandas as pd and matplotlib.pyplot as plt.\n",
    "- Use pd.read_csv() to import 'unemployment.csv', creating a DateTimeIndex from the 'date' column using parse_dates and index_col, and assign the result to data.\n",
    "- Convert data to weekly frequency using .asfreq() with the alias 'W' and show the first five rows.\n",
    "- Convert again to weekly frequency, adding the option 'bfill' and show the first five rows.\n",
    "- Create weekly series, now adding the option 'ffill', assign to weekly_ffill and show the first five rows.\n",
    "- Plot weekly_ffill starting in 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "data = pd.read_csv('unemployment.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Show first five rows of weekly series\n",
    "print(data.asfreq('W').head())\n",
    "\n",
    "# Show first five rows of weekly series with bfill option\n",
    "print(data.asfreq('W', method='bfill').head())\n",
    "\n",
    "# Create weekly series with ffill option and show first five rows\n",
    "weekly_ffill = data.asfreq('W', method='ffill')\n",
    "print(weekly_ffill.head())\n",
    "\n",
    "# Plot weekly_fill starting 2015 here \n",
    "weekly_ffill.loc['2015':].plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling & interpolation with .resample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use interpolation to create weekly employment data\n",
    "You have recently used the civilian US unemployment rate, and converted it from monthly to weekly frequency using simple forward or backfill methods.\n",
    "\n",
    "Compare your previous approach to the new .interpolate() method that you learned about in this video.\n",
    "\n",
    "Instructions\n",
    "\n",
    "We have imported pandas as pd and matplotlib.pyplot as plt for you. We have also loaded the monthly unemployment rate from 2010 to 2016 into a variable monthly.\n",
    "\n",
    "Inspect monthly using .info().\n",
    "Create a pd.date_range() with weekly dates, using the .min() and .max() of the index of monthly as start and end, respectively, and assign the result to weekly_dates.\n",
    "Apply .reindex() using weekly_dates to monthly and assign the output to weekly.\n",
    "Create new columns 'ffill' and 'interpolated' by applying .ffill() and .interpolate() to weekly.UNRATE.\n",
    "Show a plot of weekly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data here\n",
    "print(monthly.info())\n",
    "\n",
    "# Create weekly dates\n",
    "weekly_dates = pd.date_range(monthly.index.min(), monthly.index.max(), freq='W')\n",
    "\n",
    "# Reindex monthly to weekly data\n",
    "weekly = monthly.reindex(weekly_dates)\n",
    "\n",
    "# Create ffill and interpolated columns\n",
    "weekly['ffill'] = weekly.UNRATE.ffill()\n",
    "weekly['interpolated'] = weekly.UNRATE.interpolate()\n",
    "\n",
    "# Plot weekly\n",
    "weekly.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate debt/GDP and compare to unemployment\n",
    "Since you have learned how to interpolate time series, you can now apply this new skill to the quarterly debt/GDP series, and compare the result to the monthly unemployment rate.\n",
    "\n",
    "Instructions\n",
    "- We have imported pandas as pd and matplotlib.pyplot as plt for you.\n",
    "- Use pd.read_csv() to import 'debt_unemployment.csv', creating a DateTimeIndex from the 'date' column using parse_dates and index_col, and assign the result to data. print() the .info() of the data.\n",
    "- Apply .interpolate() to data and assign this to interpolated, then inspect the result.\n",
    "- Plot interpolated with 'Unemployment' on the secondary_y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import & inspect data here\n",
    "data = pd.read_csv('debt_unemployment.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "print(data.info())\n",
    "\n",
    "# Interpolate and inspect here\n",
    "interpolated = data.interpolate()\n",
    "print(interpolated.info())\n",
    "\n",
    "# Plot interpolated data here\n",
    "interpolated.plot(secondary_y='Unemployment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling & aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare weekly, monthly and annual ozone trends for NYC & LA\n",
    "You have seen in the video how to downsample and aggregate time series on air quality.\n",
    "\n",
    "First, you'll apply this new skill to ozone data for both NYC and LA since 2000 to compare the air quality trend at weekly, monthly and annual frequencies and explore how different resampling periods impact the visualization.\n",
    "\n",
    "Instructions\n",
    "- We have again imported pandas as pd and matplotlib.pyplot as plt for you.\n",
    "- Use pd.read_csv() to import 'ozone.csv' and set a DateTimeIndex based on the 'date' column using parse_dates and index_col, assign the result to ozone and inspect using .info().\n",
    "- Apply .resample() with weekly frequency ('W') to ozone, aggregate using .mean() and plot the result.\n",
    "- Repeat with monthly ('M') and annual ('A') frequencies, plotting each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "ozone = pd.read_csv('ozone.csv', parse_dates=['date'], index_col='date')\n",
    "print(ozone.info())\n",
    "\n",
    "# Calculate and plot the weekly average ozone trend\n",
    "ozone.resample('W').mean().plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the monthly average ozone trend\n",
    "ozone.resample('M').mean().plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the annual average ozone trend\n",
    "ozone.resample('Y').mean().plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare monthly average stock prices for Facebook and Google\n",
    "Now, you'll apply your new resampling skills to daily stock price series for Facebook and Google for the 2015-2016 period to compare the trend of the monthly averages.\n",
    "\n",
    "Instructions\n",
    "- We have again imported pandas as pd and matplotlib.pyplot as plt for you.\n",
    "- Use pd.read_csv() to import 'stocks.csv' and set a DateTimeIndex based on the 'date' column using parse_dates and index_col, assign the result to stocks and inspect using .info().\n",
    "- Create monthly_average by applying .resample() with monthly frequency to data, using .mean() to aggregate. Plot the result using subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect data here\n",
    "stocks = pd.read_csv('stocks.csv', parse_dates=['date'], index_col='date')\n",
    "print(stocks.info())\n",
    "\n",
    "# Calculate and plot the monthly averages\n",
    "monthly_average = stocks.resample('M').mean()\n",
    "\n",
    "\n",
    "monthly_average.plot(subplots=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare quarterly GDP growth rate and stock returns\n",
    "With your new skill to downsample and aggregate time series, you can compare higher-frequency stock price series to lower-frequency economic time series.\n",
    "\n",
    "As a first example, let's compare the quarterly GDP growth rate to the quarterly rate of return on the (resampled) Dow Jones Industrial index of 30 large US stocks.\n",
    "\n",
    "GDP growth is reported at the beginning of each quarter for the previous quarter. To calculate matching stock returns, you'll resample the stock index to quarter start frequency using the alias 'QS', and aggregating using the .first() observations.\n",
    "\n",
    "Instructions\n",
    "- As usual, we have imported pandas as pd and matplotlib.pyplot as plt for you.\n",
    "- Use pd.read_csv() to import 'gdp_growth.csv' and 'djia.csv', for both set a DateTimeIndex based on the 'date' column using parse_dates and index_col, and assign the results to gdp_growth and djia respectively, then inspect using .info().\n",
    "- Resample djia using frequency alias 'QS', aggregate using .first(), and assign to djia_quarterly.\n",
    "- Apply .pct_change() to djia_quarterly and .mul() by 100 to obtain djia_quarterly_return.\n",
    "- Use pd.concat() to concatenate gdp_growth and djia_quarterly_return along axis=1, and assign to data. Rename the columns using .columns and the new labels 'gdp' and 'djia', then .plot() the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and inspect gdp_growth here\n",
    "gdp_growth = pd.read_csv('gdp_growth.csv', parse_dates=['date'], index_col='date')\n",
    "print(gdp_growth.info())\n",
    "\n",
    "# Import and inspect djia here\n",
    "djia = pd.read_csv('djia.csv', parse_dates=['date'], index_col='date')\n",
    "print(djia.info())\n",
    "\n",
    "\n",
    "# Calculate djia quarterly returns here \n",
    "djia_quarterly = djia.resample('QS').first()\n",
    "djia_quarterly_return = djia_quarterly.pct_change().mul(100)\n",
    "\n",
    "# Concatenate, rename and plot djia_quarterly_return and gdp_growth here \n",
    "data = pd.concat([gdp_growth, djia_quarterly_return],axis=1)\n",
    "data.columns=['gdp','djia']\n",
    "data.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize monthly mean, median and standard deviation of S&P500 returns\n",
    "You have also learned how to calculate several aggregate statistics from upsampled data.\n",
    "\n",
    "Let's use this to explore how the monthly mean, median and standard deviation of daily S&P500 returns have trended over the last 10 years.\n",
    "\n",
    "Instructions\n",
    "- As usual, we have imported pandas as pd and matplotlib.pyplot as plt for you.\n",
    "- Use pd.read_csv() to import 'sp500.csv', set a DateTimeIndex based on the 'date' column using parse_dates and index_col, assign the results to sp500, and inspect using .info().\n",
    "- Convert sp500 to a pd.Series() using .squeeze(), and apply .pct_change() to calculate daily_returns.\n",
    "- .resample() daily_returns to month-end frequency (alias: 'M'), and apply .agg() to calculate 'mean', 'median', and 'std'. Assign the result to stats.\n",
    "- .plot() stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data here\n",
    "sp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\n",
    "print(sp500.info())\n",
    "\n",
    "# Calculate daily returns here\n",
    "daily_returns = sp500.squeeze().pct_change()\n",
    "\n",
    "# Resample and calculate statistics\n",
    "stats = daily_returns.resample('M').agg(['mean', 'median', 'std'])\n",
    "\n",
    "# Plot stats here\n",
    "stats.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
